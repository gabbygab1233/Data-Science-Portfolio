{"cells":[{"metadata":{"_uuid":"8c828da031d6ba875fb81d4f234433391962a6a4"},"cell_type":"markdown","source":"# Multinomail Naive Bayes Youtube spam Classifier"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nPsy = pd.read_csv('../input/Youtube01-Psy.csv')\nKaty = pd.read_csv('../input/Youtube02-KatyPerry.csv')\nEminem = pd.read_csv('../input/Youtube04-Eminem.csv')\nShakira = pd.read_csv('../input/Youtube05-Shakira.csv')\nLMFAO = pd.read_csv('../input/Youtube03-LMFAO.csv')\n\ndf_spam = pd.concat([Shakira, Eminem, Katy, Psy, LMFAO])\ndf_spam.drop('DATE', axis=1, inplace=True)\ndf_spam.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_spam.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e5eb73180cc0422646f36d312ef3dd0b21ceed1a"},"cell_type":"code","source":"df_spam['CLASS'].value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ac93cedccbea2df0f5fe520104f4280748747ac"},"cell_type":"code","source":"# This is to define the features and labels for the CountVectorizer\nX = df_spam.CONTENT\ny = df_spam.CLASS\nprint(X.shape)\nprint(y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"799fb10d8d799fb95f25f46cbc26e5c905c85d73"},"cell_type":"code","source":"# split X and y into training and testing sets\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"688460951bbebbccc5cf7f711cde27fa1ef28db5"},"cell_type":"code","source":"# import and instantiate CountVectorizer (with the default parameters)\nfrom sklearn.feature_extraction.text import CountVectorizer\nvect = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b36bd0074e52fe8871b6d2f6d0262d02ebd73ba9"},"cell_type":"code","source":"# learn training data vocabulary, then use it to create a document-term matrix\nvect.fit(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d1f5c19beee9765361abf23060af92b8c53b8fd8"},"cell_type":"code","source":"# examine the fitted vocabulary\nvect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60e5a38fb0e9fb728cb995be07662e9519100287"},"cell_type":"code","source":"# transform training data into a 'document-term matrix with a single step\nX_train_dtm = vect.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a3c7a9e8c97e14b1747c99e52a8f1817dde76ee3"},"cell_type":"code","source":"# examine the document-term matrix\nX_train_dtm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81c0c0e653f8a69cd916d6e60adee0aee656a234"},"cell_type":"code","source":"# transform testing data into a document-term matrix\n# using the transform() method\nX_test_dtm = vect.transform(X_test)\nX_test_dtm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5b64765f59fc9a68b02f7930c6247c5da3f1d627"},"cell_type":"code","source":"# import and instantiate a Multinomial Naive Bayes model\nfrom sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"140bdf883f635e4e1b61d3c16097e68aefda0ea0"},"cell_type":"code","source":"# train the model using X_train_dtm\nnb.fit(X_train_dtm, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7da80fca47a2856c89418025a878b04738726d37"},"cell_type":"code","source":"# make predictions for X_test_dtm\ny_pred_class = nb.predict(X_test_dtm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11847f7c86fb28ae0422c982a6be71b9462b1ef2"},"cell_type":"code","source":"# calculate accuracy of class predictions\nfrom sklearn import metrics\nmetrics.accuracy_score(y_test, y_pred_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b27e4eed24c1a337112e6c935631ecb4c32828cb"},"cell_type":"code","source":"# print the confusion matrix\nmetrics.confusion_matrix(y_test, y_pred_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"59fe995c73358c21d9386461e36a72647965c6ca"},"cell_type":"code","source":"# Print the classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred_class, digits=4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a89999f7abb9e145766edc4df57829199f2c0e61"},"cell_type":"code","source":"y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\ny_pred_prob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd6d3da53d0e6217ba8362d3268fa43cb13d1f2d"},"cell_type":"code","source":"# calculate AUC\nmetrics.roc_auc_score(y_test, y_pred_prob)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}